# MMU (Memory Management Unit)

A Memory Management Unit (MMU) is a very important type of internal hardware. It is used for high efficiency and secure utilization of a computer's memory devices. Another name for it is a paged memory management unit (PMMU). The main purpose of an MMU is to serve as a link or bridge between the physical memory of the computer and the central processing unit (CPU)

It is important for the smooth operation of programs and effective management of data.

## What is a Memory Management Unit (MMU)?

MMU stands for Memory management unit also known as PMMU (paged memory management unit), Every computer system has a memory management unit , it is a hardware component whose main purpose is to convert virtual addresses created by the CPU into physical addresses in the computer's memory. In simple words, it is responsible for memory management In a device as it acts as a bridge between the CPU and the RAM, which ensures that programs can run smoothly and access the required data without clashes or unauthorized access. It is usually integrated in the processor but in some cases it also constructed as a separate Integrated circuit (IC).

![MMU](https://media.geeksforgeeks.org/wp-content/uploads/20240208232601/Screenshot-2024-02-08-231740.png)

---

<br>

## Key Terminologies of MMU

- Virtual Address: The address generated by the CPU during program execution, representing a location in the virtual address space.
- Physical Address: The physical memory address of a virtual address on a computer, as determined by address translation performed by the MMU.
- Memory Paging: It is a technique used to manage memory which allows a computer to share its memory resources by storing some portion of process on disk or other secondary memory.
- Address Translation: The method by which the MMU converts virtual addresses into physical addresses so that the CPU can access the appropriate places in the computer's memory.
- Cache Memory: It is a high speed and Quick-access data storage layer, small-sized memory that speeds up CPU operations by storing frequently used data or instructions for fast processing. MMUs may interact with the cache to optimize memory access.

## Functions of Memory Management Unit(MMU)

With the growth of technology the function of Memory Management Unit (MMU) is in its role in address translation, memory protection, virtual memory management

- Address Translation: An MMU's primary job is to converting virtual addresses into physical addresses. The MMU converts virtual addresses created by running programs to corresponding physical addresses in the computer's memory. This translation is essential for the CPU to access the correct locations in RAM and interact with the necessary data.

- Memory Protection: MMUs also play a crucial role in implementing memory protection mechanisms. By implementing access control rules and regulations, they stop illegal usage of particular memory locations. By doing this, the operating system's security and data integrity are ensured.

- Virtual Memory Management: MMUs serves a part in the implementation of this method, which allows heavier programs to be executed than what can fit in the physical RAM. The system can use virtual memory to extend RAM by using a portion of the storage space on the disc and dynamically switch data between RAM and the disc as needed.

- Memory Segmentation: Memory segmentation is a feature found in certain MMUs. It splits the computer's memory into sections that have multiple authorizations and features. This segmentation provides a more granular control over memory access and aids in optimizing memory utilization.

---

<br>
<br>

# CPU Support for Fast Lookups

## TLB (TRANSLATION LOOKASIDE BUFFER)

The os instructs the mmu to perform a full loopup process reading the page tables translating physical address and handling the cpu back the correct physical address but this is unfortunately very slow. The cpu has to wait hundres or thousands of clock cycles for MMU to get it act togather and come up with an correct address translation

here is where TLB comes a small fast memory cache that stores the most frequently accessed page entrires intstead of searching the page table the system first cheaks the TLB for the entry if the desires entry is there it can quickly translate the virtual address to a physical address saving a lot of time

A TLB operates much like a hash table. It is presented with a virtual page address and produces a physical page address or failure within roughly 1/2 of a clock cycle.
In the case of a failure the memory search takes from 10 to 100 cycles. Typical miss rates are from 0.01% to 1%.

Clearly there is a limit to the number of entries in the TLB for a CPU.
The Intel Core 2 series has a total of 16 entries in a level 1 TLB and 256 entries in a level 2 TLB. The Core i7 has 64 level 1 TLB entries and 512 level 2 entries.

The AMD Athlon II CPU has 1024 TLB entries.

Given the relatively small number of TLB entries in a CPU it seems
like it would be a good idea to migrate to allocating 2 MB pages for
programs. Linux supports the use of 2 MB pages through its `HUGETLB`
option. It requires adjusting the system parameters and allocating shared
memory regions using the `SHM_HUGETLB` option. This could improve the
performance of processes using large arrays.

why 2MB gages will be better than 4KB pages

### TLB misses:

- With 4 KB pages:

  - This can result in more TLB misses because the TLB has fewer entries to store translations, meaning that when an address isn't in the TLB, the system has to access the page tables, which is much slower.

- With 2 MB pages:

  - A single 2 MB page corresponds to many 4 KB pages. As a result, fewer TLB entries are needed to cover the same amount of memory.
  - This reduces the TLB miss rate because each TLB entry covers a much larger range of memory, making it more likely that the needed translation is in the TLB.

so in summary

4 KB pages are typically better for general-purpose applications, providing finer granularity, less fragmentation, and lower
memory waste.

2 MB pages (huge pages) are beneficial for memory-intensive applications that deal with large blocks of data, as they reduce TLB misses, improve performance for large memory allocations, and reduce page table overhead.

so both have their pros & cons

---

![TLB](https://cstaleem.com/wp-content/uploads/2020/05/Translation-Look-aside-Buffer-TLB.jpg)

---

but how does the TLB know which entries to store

TLB is the combinasion of both

- `spatial locality`
- `temporal locality`

to predict what data is more likelly to be used

- `spatial locality` refers to the tendency of the program to access data locations that are closed to each other in a short period of time

for example : lets say if you are rading an book page by page when you finish one page you are more likely to to read the next page because the content you are reading flows naturally from one page to the next this is how a program memory locations that are physically close to each other

- `temporal locality` refersto the tendency of the program to access the same memory locations repeatedly within a short time frame

for example : lets go with the reading book example so temporal locality is differnet it is like frequently referring back to a paticular page or section in book for example if you are studing for an examyou may keep refrencing the same important diagram multiple times this is similiar to how program repeatedly access within a short period of time the same memory

TLB's are not perfect either once or a while you may get a question from you teacher which you may be unprepared for you might then have to flip back page by page across the whole book just to find that one fact that you needed in computer term this is known as `TLB MISS`

TLB MISSES are very inefficient which is why we try to avoid them it may take hundreds or thousends of time to look up a memory address during the TLB miss

## TLB working Model

![model](https://cstaleem.com/wp-content/uploads/2020/05/cache-and-TLB-working-together.jpg)

---

![MMU & TLB](https://sf.ezoiccdn.com/ezoimgfmt/cstaleem.com/wp-content/uploads/2020/05/MMU.jpg?ezimgfmt=ng%3Awebp%2Fngcb1%2Frs%3Adevice%2Frscb1-1)
